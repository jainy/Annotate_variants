##################################################################
# Author :  Jainy Thomas
# Date   :  August 2022
# Email  :  jainythomas1@gmail.com
# Purpose :  tool to annotate variants from a single sample VCF (generated by PLATYPUS) in GRCh37 using VEP API
##################################################################
changelog = '''changelog:
  - v1.0 = 1 Sep 2022
			--annotates VCF with a single sample 
			--human genome version : GRCh37
			--All variants in the VCF has to be annotated i.e prefiltered for quality
			--prints the output as a TSV file
			--if needed to include additional annotations, it can be added with minimal effort
			--reports minor allele frequency only if the minor allele match with the alternate allele
			--multiple alternate alleles reported for the same reference variant are also annotated
			--prints a log file of IDs failed to get annotated by VEP
			--most severe consequence also reported in addition individual transcript consequence
			--Raises error if the requested files are not found
			--cyvcf2 package checks for VCF sanity (reports missing chromosome information in VCF header)
			
'''

import argparse
from cyvcf2 import VCF
import os
import requests
import sys
import json
import time
import resource
time_start = time.perf_counter()


####################################_LOAD AND CHECK_#######################################
###########################################################################################
parser = argparse.ArgumentParser()
parser.add_argument("-v", "--vcffile", required=True, help="vcf file to be annotated")
parser.add_argument("-o", "--outfile", help="output tsv file with annotation")
args = parser.parse_args()

# Checking if the required argument files exists
if not os.path.exists(args.vcffile):
	print(f"{args.vcffile} not found! Please check if the file exists..")
	raise ValueError("File not found")


# if output file is not provided
if not args.outfile and args.vcffile:
	args.outfile = args.vcffile[:-4] + ".annotated_VEP.tsv"
# if any of the variants failed in getting annotated using VEP API it can be found in this file
API_failed_log = args.vcffile[:-4] + ".failed.log"

######################################_FUNCTIONS_##########################################
###########################################################################################
"""
# convert to hgvs format to run hgvs/VEP
#	# input params:chrom, position,REF, ALT info from VCF
#	# output params: hgvs id, type of change (for eg. substitution, insertion, deletion, both deletion and insertion)
"""
def generate_hgvs(chr,posi_start,ref,alt):
	# length of the REF and ALT is compared to identify type of variation and generate the hgvs id
	if len(ref) == 1 and len(alt) == 1:
		hgvsid = chr + ":g." + str(posi_start) + ref + ">" + alt
		return hgvsid, "substitution"
	elif len(ref) == 1 and len(alt) > 1:
		posi_end = int(posi_start) + len(ref)
		hgvsid = chr + ":g." + str(posi_start) + "_" + str(posi_end) + "ins" + alt
		return hgvsid, "insertion"
	elif len(ref) > 1 and len(alt) == 1:
		posi_end = int(posi_start) + len(ref) - 1
		hgvsid = chr + ":g." + str(posi_start) + "_" + str(posi_end) + "del"
		return hgvsid, "deletion"
	elif len(ref) > 1 and len(alt) > 1:
		posi_end = int(posi_start) + len(ref) - 1
		hgvsid = chr + ":g." + str(posi_start) + "_" + str(posi_end) + "delins" + alt
		return hgvsid, "del-ins"
	else:
		raise ValueError(f"missing REF/ ALT information in VCF for {chr}{posi_start}")

"""
input1: Number of reads supporting the variant
##FORMAT=<ID=NV,Number=.,Type=Integer,Description="Number of reads containing variant in this sample">

input2:Depth of sequence coverage at the site of variation for that sample is calculated by extracting below info from VCF
##FORMAT=<ID=NR,Number=.,Type=Integer,Description="Number of reads covering variant location in this sample">

output:  percentage of reads supporting the variant versus those supporting reference reads.
"""
def var_tot_per(vardepth,totdepth,hgvsid):
	if totdepth > 0:
		perc_var_reads = round((vardepth / totdepth) * 100, 2)
		perc_ref_reads = round(((totdepth - vardepth) / totdepth) * 100, 2)
		return perc_var_reads, perc_ref_reads
	else:
		raise ValueError(f"Total sequencing depth is 0, not possible to calculate percentage of reads for {hgvsid}")
"""
calling VEP API using POST (maximum 200 IDs can be submitted at once) for GRCh37 server as the VCF is based on GRch37
"""
def vep_api_call(datadict):
	server = "https://grch37.rest.ensembl.org"
	ext = "/vep/human/hgvs"
	headers = {"Content-Type": "application/json", "Accept": "application/json"}
	# Example format for data='{ "hgvs_notations" : ["AGT:c.803T>C", "9:g.22125503G>C" ] }')
	r = requests.post(server + ext, headers=headers, data=json.dumps(datadict))
	if not r.ok:
		r.raise_for_status()
		sys.exit()
	decoded = r.json()
	return decoded
'''
parse the API response json file to extract annotation information
input: json output from VEP API call
Output: dictionary with key as hgvs id and value as the list of annotation information obtained from json obj
	More annotations can be added to present in the tsv format (for e.g. regulatory features) by adding to list
	Minor allele frequency is reported only when the minor allele frequency of the alt variant reported, otherwise reported as null
	Impact on the transcript also collected, gene name, type of transcript, consequence
	Regulatory effects can be also be collected at this step (not included)
'''

def process_API_response(jsonobj):
	#intialising the dictionary to save the parsed info
	VEP_API_annotdict={}
	#looping through  json response
	for varinfo in jsonobj:
		# lists for collecting genenames and gene related information for each variant
		genesrelated_info = []
		genenames = []
		# getting relevant info
		hgvsid = varinfo["id"]
		most_sev_cons = varinfo["most_severe_consequence"]
		minor_allele_freq = "NULL"

		colocated_var = varinfo.get("colocated_variants")
		if colocated_var: # <class 'list'>

			# getting the alt variant info from colocated variants
			alt_var = ""
			for elements in colocated_var: # <class 'dict'>
				freqs = elements.get("frequencies")
				if freqs:
					alt_var_list = list(freqs)
					if len(alt_var_list) == 1:
						alt_var = alt_var_list[0]
					else:
						raise ValueError(f"more than one variants associated with frequency for {hgvsid}")
				# getting the minor allele
				minor_allele = elements.get("minor_allele")
				# comparing the alt and minor allele to if they are the same. if same, minor allele freq is reported
				if minor_allele and alt_var:
					if minor_allele == alt_var:
						minor_allele_freq = elements.get("minor_allele_freq")
						break
		else:
			minor_allele_freq = "NULL"
		# getting all the transcript information
		trans_conseq = varinfo.get("transcript_consequences")
		if trans_conseq:
			# looping through each transcript info
			for info in varinfo["transcript_consequences"]:
				genename = info.get("gene_symbol")
				bio_type = info.get("biotype")
				# collecting all gene names associated with a variant in a list
				if genename in genenames:
					pass
				else:
					genenames.append(genename)

				# converting list of consequence for each transcript to a string
				conseq_terms = " ".join([str(item) for item in info.get("consequence_terms")])
				# joining the respective information from a transcript (biotype, gene, consequence)
				geneimpact = ":".join((bio_type, genename, conseq_terms))
				# adding to the list of all the transcript info
				if geneimpact in genesrelated_info:
					pass
				else:
					genesrelated_info.append(geneimpact)
		else:
			# if not present, null values are added as placeholders
			genenames = "NULL"
			genesrelated_info = "NULL"

		if hgvsid in VEP_API_annotdict:
			# to check if two entries have the same ID
			raise ValueError(f"Repeated VariantIDs {hgvsid} need further evaluation")
		else:
			# gene names and related info is converted from list to string
			genes_str = ";".join([str(item) for item in genenames])
			# joining the respective information (biotype, gene, consequence) from multiple transcripts
			genesrelated_info_str = ";".join([str(item) for item in genesrelated_info])
			# information is loaded to dictionary of parsed information from VEP API response
			VEP_API_annotdict[hgvsid] = [most_sev_cons, minor_allele_freq, genes_str, genesrelated_info_str]
	return VEP_API_annotdict
'''
print the final output
input: final dictionary all the variant info and annotation info, output file
output: tsv file 
headers are hard coded
'''
def print_finaldict(annotdict,file):
	with open(file, "w+") as fobj:
		fobj.write("hgvsID\tChrom\tposition\tRef\tAlt\tType_of_Variation\tvariant_depth\tTotal_read_depth\tperc_variant_depth\tperc_ref_depth\tmost_severe_consequence\tminor_allele_frequency\tgenes\tgenes_effect\n")
		for hgvsIDs in annotdict:
			fobj.write(hgvsIDs + "\t")
			fobj.write("\t".join(map(str, annotdict[hgvsIDs])))
			fobj.write("\n")
'''
check if all the hgvs ids in request list had a response from API
input: hgvs ids requested, hgvs ids in the parsed dictionary (from each request of 200)
output: missing ones are stored in a list
'''
def create_error_list(hgvs_request_list,hgvs_response_dict):
	failed_list = []
	for ids in hgvs_request_list:
		if ids in hgvs_response_dict:
			continue
		else:
			failed_list.append(ids)
	return failed_list
'''
The missing hgvs ids that did not get a VEP response is printed to the log file
input: list of errored ids, logfile
output: files containing hgvs ids for which there was no VEP response
'''
def write_error_log(err_list,logfile):
	with open(logfile,"w+") as wobj:
		for errid in err_list:
			wobj.write(errid + "\n")



#########################################_MAIN_############################################
###########################################################################################


# dictionary to hold the variant info from VCF and VEP
variant_infodict = {}
# to count the number of variants, so when reach 200 do post to VEP API
count = 0
# dictionary to do VEP API request
APIgroup_request = {}
APIgroup_request["hgvs_notations"] = []
# list to hold hgvs ids for API request
request_list = []
# list to hold the hgvs ids that were failed to get annotated
failedtoannotate = []
# input VCF is read using cyvcf2 package
print("----Reading through the VCF file----")
for variant in VCF(args.vcffile):
	count += 1
	# to separate multi-allelic and single allelic variants
	# single allelic variants are dealt here
	if len(variant.ALT) == 1:
		hgvs_ID, vartype = generate_hgvs(variant.CHROM, variant.POS, variant.REF, variant.ALT[0])
		varVCFinfo = "\t".join((variant.CHROM, str(variant.POS), variant.REF, variant.ALT[0]))
		# both are returned as array of array (numpy)
		seq_depth = variant.format('NR')
		var_depth = variant.format('NV')

		# since there is only one sample it will be the first element in the array and only one read depth value
		s1_vardepth = var_depth[0][0]
		s1_totdepth = seq_depth[0][0]
		# percentage of variant and ref reads are calculated
		perc_vari_reads, perc_refe_reads = var_tot_per(s1_vardepth, s1_totdepth,hgvs_ID)
		# if no duplicates existed, the VCF info is stored, also adding to VEP API request list
		if hgvs_ID in variant_infodict:
			raise ValueError(f"Repeated VariantIDs {hgvs_ID} need further evaluation")
		else:
			variant_infodict[hgvs_ID] = [varVCFinfo, vartype, s1_vardepth, s1_totdepth, perc_vari_reads, perc_refe_reads]
			request_list.append(hgvs_ID)

	# To handle multiple variants,  separate hgvs ids are created for each alternate variant
	elif len(variant.ALT) > 1:
		# looping through each variant in alt
		varnum = 0
		for var_alt in variant.ALT:
			hgvs_ID, vartype = generate_hgvs(variant.CHROM, variant.POS, variant.REF, var_alt)
			varVCFinfo = "\t".join((variant.CHROM, str(variant.POS), variant.REF, var_alt))
			# both info are returned as array of array
			seq_depth = variant.format('NR')
			var_depth = variant.format('NV')
			s1_vardepth = var_depth[0][varnum]
			s1_totdepth = seq_depth[0][varnum]
			# percentage of variant and ref reads are calculated
			perc_vari_reads, perc_refe_reads = var_tot_per(s1_vardepth, s1_totdepth, hgvs_ID)

			# if no duplicates existed, the VCF info is stored, also adding to VEP API request list
			if hgvs_ID in variant_infodict:
				raise ValueError(f"Repeated VariantIDs {hgvs_ID}, need further evaluation")
			else:
				variant_infodict[hgvs_ID] = [varVCFinfo, vartype, s1_vardepth, s1_totdepth, perc_vari_reads, perc_refe_reads]
				request_list.append(hgvs_ID)
			# extracting corresponding depth for each alt allele
			varnum += 1

	# check if count reached 200 to API post
	if count == 200:
		print("---sending API request and gathering response---")
		# list of hgvs IDs is loaded
		APIgroup_request["hgvs_notations"] = request_list
		# response is collected as json
		jsonobj = vep_api_call(APIgroup_request)
		# json is parsed and annotation information is collected in a dictionary
		VEP_annotdict = process_API_response(jsonobj)

		# merge the annotation info with the variant info from VCF
		for ids in VEP_annotdict:

			if ids in variant_infodict:
				infoVCF = variant_infodict[ids]
				infoVEP = VEP_annotdict[ids]
				finalinfo = infoVCF + infoVEP
				variant_infodict[ids] = finalinfo
			else:
				continue

		# to collect the next set of hgvs ids
		count = 0
		# hgvs ids in request list and VEP annotated dictionary is compared to find missing
		errorlist = create_error_list(request_list,VEP_annotdict)
		if errorlist != None:
			failedtoannotate.extend(errorlist)
		request_list = []
	else:
		continue
# Doing the API call for final group of variants that do not satisfy the given count number (200)
APIgroup_request["hgvs_notations"] = request_list
jsonobj = vep_api_call(APIgroup_request)
VEP_annotdict = process_API_response(jsonobj)

# merge the annotation info with the variant info from VCF final group of variants
for ids in VEP_annotdict:
	if ids in variant_infodict:
		infoVCF = variant_infodict[ids]
		infoVEP = VEP_annotdict[ids]
		finalinfo = infoVCF + infoVEP
		variant_infodict[ids] = finalinfo
	else:
		continue
errorlist = create_error_list(request_list,VEP_annotdict)
if errorlist != None:
	failedtoannotate.extend(errorlist)
# print the final annotated dictionary as a tsv file
print_finaldict(variant_infodict,args.outfile)
#  if some variants failed to get annotated, those are listed in the log file
if errorlist != None:
	write_error_log(errorlist,API_failed_log)

print("----------DONE-----------")
time_elapsed = (time.perf_counter() - time_start)
memMb=resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024.0/1024.0
print ("%5.1f secs %5.1f MByte" % (time_elapsed,memMb))